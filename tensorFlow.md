# TensorFlowJS
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/TensorFlow_Logo_with_text.png/274px-TensorFlow_Logo_with_text.png">
TensorFlow - відкрита програмна бібліотека для машинного навчання, розроблена компанією Google для вирішення завдань побудови і тренування нейронної мережі з метою автоматичного знаходження та класифікації образів, досягаючи якості людського сприйняття . Застосовується як для досліджень, так і для розробки власних продуктів Google. Основний API для роботи з бібліотекою реалізований для Python, також існують реалізації для R, C Sharp, C ++, Haskell, Java, Go і Swift.

Є продовженням закритого проекту DistBelief . Спочатку TensorFlow була розроблена командою Google Brain для внутрішнього використання в Google, в 2015 році система була переведена в вільний доступ з відкритою ліцензією Apache 2.0 

В даний час Python займає домінуючу позицію для машинного навчання. Однак, якщо ви є JS-розробником і зацікавлені зануритися в цей світ, то не обов'язково включати в свій арсенал нову мову програмування, в зв'язку з появою TensorFlow.js.

Переваги використання TensorFlow.js в браузері

інтерактивність - браузер має багато інструментів для візуалізації процесів, що відбуваються (графіки, анімація та ін.);

сенсори - браузер має прямий доступ до сенсорам пристрої (камера, GPS, акселерометр і ін.);

захищеність даних користувача - немає необхідності відправляти оброблювані дані на сервер;

сумісність з моделями, створеними на Python.

# Продуктивність

Одним з головних питань постає питання продуктивності.

У зв'язку з тим, що машинне навчання - це, по суті, виконання різного роду математичних операцій з матрично-подібними даними (тензорами), то бібліотека для такого роду обчислень в браузері використовує WebGL. Це значно збільшує продуктивність, якби ті ж операції здійснювалися на чистому JS. Природно, бібліотека має fallback на той випадок, якщо WebGL з якихось причин не підтримується в браузері (на момент написання статті caniuse показує, що підтримка WebGL є у 97.94% користувачів).

Для підвищення продуктивності на Node.js використовується native-binding з TensorFlow. Тут в якості акселераторів можуть служити CPU, GPU і TPU (Tensor Processing Unit)

# архітектура TensorFlow.js

Lowest Layer - цей шар відповідальний за параллелизация обчислень при здійсненні математичних операцій над тензорами.

The Ops API - надає АПИ для здійснення математичних операцій над тензорами.

Layers API - дозволяє створювати складні моделі нейронних мереж з використанням різних видів шарів (dense, convolutional). Цей шар схожий на API Keras на Python і має можливість завантажувати попередньо навчені мережі на базі Keras Python.
<img src="https://habrastorage.org/webt/k-/rg/up/k-rgupjbjhzrftn28uz7bqkhqae.png">

# Що таке тензор
Абсолютно кожен стикався з тензорами в математиці - це скаляр, вектор, 2D - матриця, 3D - матриця. Тензор - це узагальнене поняття всього перерахованого. Це контейнер даних, який містить однорідні за типом дані (tensorflow підтримує int32, float32, bool, complex64, string) і має певну форму (кількість осей (ранк) і кількість елементів у кожній з осей). Нижче ми розглянемо тензори аж до 3D-матриць, але так як це узагальнення, кількість осей у тензора може бути стільки скільки завгодно: 5D, 6D, ... ND.

# Історія
Закрита система машинного навчання DistBelief розроблялася Google Brain для внутрішніх проектів з 2011 року для роботи з нейронними мережами глибокого навчання. Вона стала використовуватися в багатьох дослідницьких і комерційних проектах групи фірм холдингу Alphabet . Після успіху DistBelief, фірма Google вирішила вивести проект на новий рівень, і для рефакторінга виділила групу з кількох розробників, в яку увійшов Джефф Дін; метою групи було спрощення і оптимізація кодів бібліотеки, збільшення надійності та зручності користування. Нова бібліотека отримала назву TensorFlow .У 2013 году до проекту прієднався Джеффрі Хінтон - навчань, під керівніцтвом которого в 2009 году БУВ Створений метод узагальненого зворотнього Поширення помилки и ряд других поліпшень, что дозволили істотно поліпшіті точність нейронних мереж (что прізвело, зокрема, до зниженя похібкі в розпізнаванні мови на 25 %) .




Бібліотека TensorFlow написана під величезна кількість мов: Python, С / C ++, JavaScript, Go, Java, Swift, C #, Haskell, Julia, R, Scala, Rust, OCaml, Crystal. Але ми виберемо безумовно кращий - JavaScript.

TensorFlow можна під'єднати до нашої сторінці, підключивши скрипт з CDN:
```
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"></script>
```
Або використовувати npm:
```
npm install @tensorflow/tfjs-node - для процесу node (веб-сайту);
npm install @tensorflow/tfjs-node-gpu(Linux CUDA) - для GPU, але тільки якщо на машині Linux і відеокарта підтримує технологію CUDA. Обов'язково упевніться, CUDA Compute Capability відповідає вашій бібліотеці, щоб не виявилося, що дороге залізо не підходить.
npm install @tensorflow/tfjs (Slowest / Browser) - для браузера без використання Node.js.
```
Для роботи з TensorFlow JS достатньо імпортувати один з перерахованих вище модулів. Ви побачите багато прикладів коду, де імпортується все підряд. Не треба так робити, вибирайте і імпортуйте тільки один.

# тензори

Коли початкові дані готові, перше, що потрібно зробити, - імпортувати TensorFlow . Скористаємося tensorflow / tfjs-node-gpu, щоб отримати прискорення за рахунок потужностей відеокарти.
```
// Импортируйте @tensorflow/tfjs-node-gpu для node.js
const tf = require('@tensorflow/tfjs');
```
const a = [[1,2], [3,4]];

Є двовимірний масив даних - з ним і будемо працювати.

Наступна важлива річ, яку необхідно зробити, - створити тензор . В даному випадку тензор створюється рангу 2, тобто фактично двовимірний масив. Передаємо дані і отримуємо тензор 2х2.
```
// Создаем rank-2 тензор (матрица/массив)
const b = tf.tensor([[1,2], [3,4]]);
console.log('shape:', b.shape);
b.print()
```
Зауважте, що викликається метод print, а не console.log, тому що b(тензор, який ми створили) - це не звичайний об'єкт, а саме тензор. У нього свої методи і властивості.

Також можна створити тензор з плоского масиву і тримати його форму в розумі, скажімо так. Тобто оголосити форму - двовимірний масив - передавати просто плоский масив і вказувати безпосередньо форму. Результат буде той же.

Завдяки тому, що дані і форма можуть зберігатися окремо, можна змінювати форму тензора. Чи можемо викликати метод reshapeі поміняти форму з 2х2 на 4х1.

Наступний важливий етап - вивести дані , повернути їх назад в реальний світ.
```
// Вывод данных
const g = tf.tensor([[1,2], [3,4]]);
g.data().then((raw) => {
  console.log('async raw value of g:', raw);
});
console.log('raw value of g:', g.dataSync());
console.log('raw multidimensional value of g:', g.arraySync());
```
Код всіх трьох етапів.

Метод data повертає promise. Після того як він зарезолвітся, отримаємо безпосереднє значення raw value, але отримаємо його асинхронно. Якщо захочемо, можемо отримати синхронно, але пам'ятайте, що тут ви можете втратити в продуктивності, тому по можливості використовуйте асинхронні методи.

Метод data Syncзавжди повертає дані у форматі плоского масиву. А якщо ми хочемо повернути дані в тому форматі, в якому вони зберігаються в тензор, потрібно викликатиarraySync.

# Оператори

Всі оператори в TensorFlow immutable за замовчуванням , тобто в кожної операції завжди повертається новий тензор. Вище просто беремо наш масив і зводимо в квадрат всі його елементи.
```
// Все операторы Immutable
const x = tf.tensor([1,2,3,4]);
const y = x.square(); // tf.square(x);
y.print();
```
Навіщо такі складнощі для простих математичних операцій? Всі оператори, які нам потрібні - сума, медіана та ін. - там є. Потрібно це тому, що насправді тензор і цей підхід дозволяє створити граф обчислень і виконувати обчислення не відразу, а на WebGL (в браузері) або CUDA (Node.js на машині). Тобто фактично використовувати Hardware Acceleration непомітно для нас і при необхідності робити fallback на CPU. Саме чудове, що ні про що про це нам не потрібно думати. Нам треба всього-лише вивчити tfjs API.

Тепер найважливіше - модель.

# Модель

Найпростіший спосіб створення моделі - Sequential, тобто послідовна модель, коли з одного шару дані передаються в наступний шар, і з нього - в наступний шар. Тут використовуються найпростіші шари, які тільки бувають.
Шар сам по собі - це всього лише абстракція над тензорами і операторами. Грубо кажучи, це helper-функції, які ховають від вас величезна кількість математики.
```
// Последовательные слои модели
const model = tf.sequential({
  layers: [
    tf.layers.dense({
      inputShape: [784],
      units: 32,
      activation: 'relu'
    }),
    tf.layers.dense({
      units: 10,
      activation: 'softmax'
    })
  ]
});
```
Давайте спробуємо зрозуміти, як працювати з моделлю, не вникаючи з особливості реалізації.

Спочатку вказуємо форму даних, які потрапляють в нейронну мережу - inputShape- це обов'язковий параметр. Вказуємо units- кількість багатовимірних масивів і активаційну функцію.

Функція reluчудова тим, що знайшли її випадково - спробували, запрацювало краще, і дуже довго потім шукали математичне пояснення, чому так виходить.

Для останнього шару, коли робимо категорію, часто використовується фукция softmax - вона дуже добре підходить для виведення відповіді в форматі One-Hot Encoding. Після того, як модель створена, викликаємоmodel.summary(), Щоб переконатися, що модель зібралася за потрібне способом. В особливо складних ситуаціях можна підійти до створення моделі, використовуючи функціональне програмування.
```
// Функциональный подход

const input = tf.input({ shape: [784] });
const dense1 = tf.layers.dense({ units: 32, activation: 'relu' }).apply(input);
const dense2 = tf.layers.dense({ units: 10, activation: 'softmax' }).apply(dense1);
const model = tf.model({ inputs: input, outputs: dense2 });
```
Якщо потрібно створити особливо складну модель, можна використовувати функціональний підхід: кожен раз кожен шар - це нова змінна. У приклад вручну беремо наступний шар і до нього застосовуємо попередній шар, завдяки чому можемо вибудовувати більш складні архітектури. Трохи пізніше покажу, де це може стати в нагоді.

Наступна дуже важлива деталь - ми передаємо в модель вхідні і вихідні шари, тобто шари, які входять в нейронну мережу, і шари, які є шарами для відповіді.

Після цього важливий крок - скомпілювати модель . Давайте спробуємо зрозуміти, що таке компіляція в термінах tfjs.

Пам'ятайте, ми намагалися підібрати потрібні значення в нашій нейронної мережі. Підбирати їх треба не випадково. Вони підбираються певним способом, як - каже функція-оптімайзер.
```
// Компилируем модель (подготавливаем к тренировке)
model.compile({
  optimizer: 'sgd',
  loss: 'categoricalCrossentropy',
  metrics: ['accuracy']
});
```
Код опису послідовних шарів і компіляції.

Проілюструю, що таке оптімайзер і що таке loss-функція.
<img src="https://habrastorage.org/webt/se/lt/1l/selt1lv8ppxvokzopux387dp0os.png">
Оптімайзер - це вся карта. Вона дозволяє не просто випадково бігати і шукати значення, а робити це з розумом, за певним алгоритмом.

Loss-функція - це шлях, по якому ми шукаємо оптимальне значення (маленька чорна стрілочка). Вона допомагає зрозуміти, які значення градієнта використовувати для навчання нашої нейронної мережі.

У майбутньому, коли ви освоїте нейронні мережі, то будете писати loss-функцію самі. Велика частина успіху нейронної мережі залежить від того, як добре написана ця функція. Але це вже окрема історія. Давайте почнемо з простого.
# Приклад навчання мережі

Згенеруємо випадкові дані і випадкові ж відповіді (labels). Викличемо модуль fit, передамо дані, відповіді і кілька важливих параметрів:

epochs - 5 разів, тобто, грубо кажучи, 5 раз проведемо повноцінне тренування;
batchSize, Який говорить про те, скільки ваг можна змінити за один раз підняти - скільки елементів одночасно обробити. Чим краще відеокарта, чим більше в ній пам'яті, тим більше можна виставити batchSize.
```
// Подготавливаем данные
const data = tf.randomNormal([100, 784]);
const labels = tf.randomNormal([100, 10]);

// Тренируем модель
model.fit(data, labels, {
  epochs: 5,
  batchSize: 32
}).then(info => {
  console.log('Точность обученной модели:', info.history.acc);
})
```
Model.fitасинхронний метод, повертає promise. Але можна використовувати async / await і чекати виконання таким чином.

Далі - використання . Ми натренували нашу модель, далі беремо дані, які хочемо обробити, і викликаємо методpredict, говоримо: «Передбач, що там насправді?», І завдяки цьому отримуємо результат.

# стандартна структура

У кожної нейронної мережі є три основних файлу:

index.js - файл, в якому зберігаються всі параметри нейронної мережі;
model.js - файл, в якому зберігається безпосередньо модель і її архітектура;
data.js - файл, де збираються, обробляються дані, і вбудовуються в нашу систему.

Підготувати до неї дані, тобто зробити embedding, підлаштувати їх під архітектуру.
Налаштувати Hyper-параметри (далі розповім, що це означає).
Тренувати / навчати кожну нейронну мережу (в кожної моделі можуть бути свої нюанси).
Застосовувати нейронну модель, і знову ж таки застосовувати можна по-різному.

# вибираємо модель

Почнемо з базових варіантів, які часто будуть вам зустрічатися.

# Глибокий щільний

Це популярний приклад глибокої нейронної мережі. Робиться все досить просто: є публічно доступна набір даних - MNIST dataset.
<img src="https://habrastorage.org/webt/6g/yu/-4/6gyu-4wjgg4zfvf8w7byjx_z5yw.jpeg">
Це розмічені картинки з цифрами, на базі яких зручно навчати нейронну мережу.

У відповідності з архітектурою One-Hot Encoding кодируем кожен з останніх шарів. Цифр 10 - відповідно, буде 10 останніх шарів в кінці. На вхід подаємо просто чорно-білі картинки, все це дуже схоже, на те про що ми говорили на початку.

```
const model = tf.sequential({ 
  layers: [ 
    tf.layers.dense({ 
      inputShape: [784], units: 512, 
      activation: 'relu' 
    }), 
    tf.layers.dense({ 
      units: 256, activation: 'relu' 
    }), 
     tf.layers.dense({ 
      units: 10, activation: 'softmax' 
    }), 
  ] 
}); 
```
Випрямляємо картинку в одновимірний масив, отримуємо 784 елементів. В одному шарі 512 масивів. Функція активації 'relu'.

У наступного шару масивів трохи менше (256), активаційний шар теж 'relu'. Ми зменшили кількість масивів, щоб шукати більш загальні характеристики. Нейронна мережі треба підказувати, як навчатися, і змушувати приймати більш серйозне, загальне рішення, тому що сама вона це робити не буде.

В кінці робимо 10 матриць і використовуємо softmax-активацію для One-Hot Encoding - цей вид активації добре працює з цим видом кодування відповіді.

Глибокі мережі дозволяють правильно розпізнати 80-90% картинок - хочеться більшого. Людина розпізнає з якістю приблизно в 96%. Чи можуть нейронні мережі наздогнати і перегнати людини?
